# Algorithm

Algorithm is a well-defined finite number of steps to solve a computational problem. It takes values as input and provide output. 

 
Creating an algorithm is an art which may never be fully automated.

We can describe an algorithm in many ways. We can use a natural language like English, although if we select this option. We must make sure that the resulting instructions are definite.
Graphic representations called flowcharts are another possibility, but they work well only if the algorithm is small and simple.

**How to analyze Algorithm?**

Analysis of algorithms or performance analysis refers to the task of determining how much computing time and storage an algorithm requires.  This is challenging area which sometimes requires great mathematical skill. Question such as how an algorithm performs in the best case, in the worst case, or on the average are typical.

**How to validate Algorithm?**

Once an algorithm is designed (devised), it is necessary to show that it computes the correct answer for all possible legal inputs. We refer to this process an algorithm validation. The purpose of the validation is to assure us that this algorithm will work correctly independently of the issues concerning the programming language it will eventually be written in. A program can be written and a second phase begins. This phase is referred as to as program proving or sometimes as program verification.

**How to test a program?**

Testing a program consist two phases debugging and profiling (or performance measurement). Debugging is the process of executing programs on sample data sets to determine whether faulty results occur and, if so, to correct them.

A proof of correctness is much more valuable than a thousand test (if that proof is correct). Since it guarantees that the program will work correctly for all possible inputs.

### **Asymptotic notations**

!https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1c53ea46-e8d6-436c-82c4-ee5abd39dc54/Untitled.png

!https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5e8685a2-2cce-4948-b48b-790eb233d245/Untitled.png

Asymptotic notations are the mathematical notations used to describe the running time of an algorithm, when the input tends towards a particular value or a limiting.

There are mainly three kinds of asymptotic notations

1. Big-O notation
2. Omega Ω notation
3. Theta Ø notation

**F(n) = O(g(n)),** it says that the growth rate of f(n) is less than or equal to the growth rate of g(n).

1. **Omega notation (lower bound)**

**F(n) = Ω(g(n))** it, says at the growth rate of f(n) is greater than or equal to the growth rate of g(n).

1. **Theta notation (same order)**

**F(n) =** Ø **g(n)**Is say that the growth rate of f(n) is equal to , the growth of g(n).

**Categories of an algorithm**

1. Constant time O(1) algorithms
2. Logarithmic time O(log n) algorithms
3. Linear time O(n) algorithms
4. Exponential time O(k^n), for k>1 algorithms
5. Polynomial time O(n^k) for k>1 algorithms
6. Many algorithms are O(n log n)

!https://s3-us-west-2.amazonaws.com/secure.notion-static.com/86b4c63d-760c-414a-ab87-a1532bd632a0/Untitled.png

[noRyiZ4jV.avif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f5c773d7-6f60-4983-a067-f805b2112b08/noRyiZ4jV.avif)